{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neuvoo_test2.py\n",
    "# test script for testing neuvoo scraper class\n",
    "# author Aniket Chaudhari\n",
    "\n",
    "from souper import *  # souper module\n",
    "from neuvoo_job import *  # neuvoo job field\n",
    "import re  # regular expressions\n",
    "from urllib.parse import urlparse  # urlparser\n",
    "'''\n",
    "global vars\n",
    "'''\n",
    "\n",
    "# target url\n",
    "url = 'http://www.neuvoo.co.in/jobs/?'\n",
    "\n",
    "payload = {}\n",
    "# page offset no\n",
    "page_no = 1\n",
    "# redirected_url\n",
    "redirected_url = ''\n",
    "# soup\n",
    "soup = None\n",
    "#jobcards\n",
    "jobCards = []\n",
    "\n",
    "def set_last_url(lurl):\n",
    "    parsed_uri = urlparse(lurl)\n",
    "    global redirected_url\n",
    "    redirected_url = '{uri.scheme}://{uri.netloc}/'.format(uri=parsed_uri)[:-1]\n",
    "\n",
    "def set_payload(query,location,page):\n",
    "    global payload\n",
    "    if page != '1':\n",
    "        payload = {\n",
    "            \"k\":query,\n",
    "            \"l\":location,\n",
    "            \"p\":str(page+1)+'0'\n",
    "        }\n",
    "    else:\n",
    "        payload = {\n",
    "            \"k\":query,\n",
    "            \"l\":location\n",
    "        }\n",
    "\n",
    "'''\n",
    "end global vars\n",
    "'''\n",
    "\n",
    "# payload setter\n",
    "# if page_no != 1:\n",
    "#     start_offset = (page_no + 1)\n",
    "#     payload[\"start\"] = str(start_offset)+'0'\n",
    "\n",
    "\n",
    "\n",
    "class neuvooScraper():\n",
    "    jobj = None\n",
    "    scraped_jobs = 0\n",
    "\n",
    "    def __init__(self, jobcard):\n",
    "        # set attrs\n",
    "        # set attrs\n",
    "        title, link = self.get_title(jobcard)\n",
    "        employer = self.get_employer(jobcard)\n",
    "        address = self.get_address(jobcard)\n",
    "        desc = self.get_desc(jobcard)\n",
    "        posted = self.get_posted(jobcard)\n",
    "        \n",
    "        scraped = self.get_jobcount()\n",
    "        # instanciate\n",
    "        self.jobj = neuvoo_Job(scraped, title, link, employer, address,\n",
    "                               desc, posted)\n",
    "\n",
    "    # method get_job\n",
    "    # returns neuvoo_Job object\n",
    "    def get_job(self):\n",
    "        return self.jobj\n",
    "\n",
    "    # method get_title\n",
    "    # returns title string\n",
    "    def get_title(self, jobcard):\n",
    "        jobtitle = jobcard.findAll(\"div\", {\"class\": \"j-title\"})\n",
    "        link = jobcard.findAll(\"a\", {\"class\": \"gojob\"})\n",
    "        global redirected_url\n",
    "        if len(jobtitle) != 0:\n",
    "            return jobtitle[0].text, redirected_url+''+ link[0][\"href\"]\n",
    "        else:\n",
    "            return ''\n",
    "\n",
    "    # method get_employer\n",
    "    # returns employer string\n",
    "    def get_employer(self, jobcard):\n",
    "        job_employer = jobcard.findAll(\"div\", {\"class\": \"j-empname\"})\n",
    "        if len(job_employer) != 0:\n",
    "            if '\\n' in job_employer:\n",
    "                return job_employer[0].text.lstrip()\n",
    "            else:\n",
    "                return job_employer[0].text.replace('\\n', '').lstrip()\n",
    "        else:\n",
    "            return ''\n",
    "\n",
    "    # method get_address\n",
    "    # returns address string\n",
    "    def get_address(self, jobcard):\n",
    "        job_address_div = jobcard.findAll(\"div\", {\"class\": \"j-location\"})\n",
    "        if len(job_address_div) != 0:\n",
    "            return job_address_div[0].text\n",
    "        else:\n",
    "            return ''\n",
    "\n",
    "    # method get_desc\n",
    "    # returns description string\n",
    "    def get_desc(self, jobcard):\n",
    "        job_desc = jobcard.findAll(\"div\", {\"class\": \"j-snippet\"})\n",
    "\n",
    "        if len(job_desc) != 0:\n",
    "            return job_desc[0].text.lstrip()\n",
    "        else:\n",
    "            return ''\n",
    "\n",
    "    # method get_posted\n",
    "    # returns date string\n",
    "    def get_posted(self, jobcard):\n",
    "        job_posted = jobcard.findAll(\"div\", {\"class\": \"j-date\"})\n",
    "        if len(job_posted) != 0:\n",
    "            return job_posted[0].text\n",
    "        else:\n",
    "            return ''\n",
    "    \n",
    "\n",
    "    # method get_jobcount\n",
    "    # returns count of scraped jobs int\n",
    "    def get_jobcount(self):\n",
    "        global soup\n",
    "        job_count = soup.findAll(\"span\", {\"class\": \"total-job\"})\n",
    "        if len(job_count) != 0:\n",
    "            num = re.findall(r'\\d+', job_count[0].text)\n",
    "            if len(num) > 2:\n",
    "                return str(num[1] + num[2])\n",
    "            else:\n",
    "                return str(num[1])\n",
    "        else:\n",
    "            return ''\n",
    "    # end neuvooScraper class\n",
    "\n",
    "#main scrape method neuvoo.com\n",
    "def scrape_neuvoo(j_query, j_location, j_page):\n",
    "    global url,payload,soup,jobCards,redirected_url\n",
    "\n",
    "\n",
    "    set_payload(j_query, j_location, j_page)\n",
    "\n",
    "    soup,neuvoo_last_url = Souper(url, payload).get_soup()  # setting initial soup\n",
    "\n",
    "    set_last_url(neuvoo_last_url)  # setting initial l_url\n",
    "\n",
    "\n",
    "    # parsing the redirected url\n",
    "\n",
    "    # jobcard\n",
    "    jobCards = soup.findAll(\"div\", {\"class\": \"job\"})\n",
    "\n",
    "\n",
    "    # check for an international job\n",
    "    #url = 'https://www.neuvoo.co.in/jobs?'\n",
    "    if len(jobCards) == 0:\n",
    "        # check for international domain link\n",
    "        other_job = soup.findAll(\"p\", {\"class\": \"oocs\"})\n",
    "\n",
    "        if len(other_job) != 0:\n",
    "            other_job_link = soup.findAll(\"p\", {\"class\": \"oocs\"})[0].find('a')['href']\n",
    "            url = other_job_link\n",
    "            soup = Souper(url, payload).get_soup()  # setting initial soup\n",
    "            # setting initial l_url\n",
    "            set_last_url(neuvoo_last_url)\n",
    "            jobCards = soup.findAll(\"div\", {\"class\": \"job\"})\n",
    "\n",
    "\n",
    "    #iteration on jobCards\n",
    "    job_arr = []\n",
    "    # json job array; containing json job objects\n",
    "    json_arr = []\n",
    "\n",
    "    neuvoo_job_count = 0\n",
    "\n",
    "    for i in jobCards:\n",
    "        # populating the job and json arrays\n",
    "        job_arr.append(neuvooScraper(i).get_job())\n",
    "        neuvoo_job_count = neuvooScraper(i).get_jobcount()\n",
    "        json_arr.append(neuvooScraper(i).get_job().get_json())\n",
    "\n",
    "    #def ret_json_arr():\n",
    "    return neuvoo_job_count,json_arr\n",
    "\n",
    "# #calling the main method\n",
    "#j_count, j_data = scrape_neuvoo(\"software engineer\",\"delhi india\",\"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
